{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating functions to be used in querying and transforming BigQuery tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datalab --upgrade\n",
    "#\n",
    "%load_ext google.datalab.kernel\n",
    "#\n",
    "from google.datalab import bigquery\n",
    "import google.datalab.bigquery as bq\n",
    "#\n",
    "set_datalab_project_id('project_id') # enter your project id here\n",
    "#\n",
    "%reload_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.datalab as dl\n",
    "import google.datalab.bigquery as bq\n",
    "import google.datalab.storage as storage\n",
    "\n",
    "#Import python pandas for data wrangling\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Table Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Creating the function to read and create a pivot table query from a table given the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the database name, table name, index column, columns to pivot and value column (by default 1)\n",
    "def bq_custom_pivot(db_name, # enter the input database name\n",
    "                    table_name, # input table name\n",
    "                    index_cols, # index columns as a list: ['col1', 'col2']\n",
    "                    col_def, # field to convert to column\n",
    "                    val_def = 1, # value field to aggregate (By default it will carry out one-hot encoding)\n",
    "                    val_agg = 'SUM'): # Aggregation function\n",
    "        \n",
    "        ## Reading in the indexes mentioned\n",
    "        idx_fin = \"\"\n",
    "        for i in range(0, len(index_cols)):\n",
    "            idx = str(index_cols[i])\n",
    "\n",
    "            if i == max(range(0, len(index_cols))):\n",
    "                idx_fin += idx\n",
    "            else:\n",
    "                idx_fin += idx + \", \"\n",
    "        \n",
    "        ## Identifying the columns to generate case when statements\n",
    "        col_sql = \"SELECT DISTINCT \" + col_def + \" FROM `\" + db_name + \".\" + table_name + \"`\" + \" WHERE \" + col_def + \" IS NOT NULL\"\n",
    "        col_query = bq.Query(col_sql)\n",
    "        col_df = col_query.execute(output_options=bq.QueryOutput.dataframe()).result()\n",
    "        \n",
    "        ## Generating the case when statements\n",
    "        case_qry = \"\"\n",
    "        sel_qry = \"\"\n",
    "        \n",
    "        for i in range(0,len(col_df.iloc[:,0])):\n",
    "            \n",
    "            col_sel = str(col_df.iloc[i, 0])\n",
    "            col_clean = re.sub('[^A-Za-z0-9]+', '', col_sel)\n",
    "            \n",
    "            if type(col_df.iloc[i, 0]) == str:\n",
    "                case_prt = \"(CASE WHEN \" + col_def + \" = \" + \"\\\"\" + col_sel + \"\\\"\" + \" THEN \" + val_def + \" ELSE 0 END) AS \" + \"Col_\" + col_clean\n",
    "            else:\n",
    "                case_prt = \"(CASE WHEN \" + col_def + \" = \" + col_sel + \" THEN \" + val_def + \" ELSE 0 END) AS \" + \"Col_\" + col_clean\n",
    "            \n",
    "            sel_prt = \"Col_\" + col_clean\n",
    "\n",
    "            if i == max(range(0,len(col_df.iloc[:,0]))):\n",
    "                case_qry += case_prt\n",
    "                sel_qry += sel_prt\n",
    "\n",
    "            elif i == max(range(0,len(col_df.iloc[:,0]))) - 1:\n",
    "                case_qry += case_prt + \", \"\n",
    "                sel_qry += sel_prt +\", \"\n",
    "                \n",
    "                \n",
    "            else: \n",
    "                case_qry += case_prt + \", \"\n",
    "                sel_qry += sel_prt +\", \"\n",
    "                \n",
    "        agg_qry = \"\"\n",
    "        for m in range(0, len(col_df.iloc[:, 0])):\n",
    "            col_sel = str(col_df.iloc[m, 0])\n",
    "            col_clean = re.sub('[^A-Za-z0-9]+', '', col_sel)\n",
    "            agg_prt = val_agg + \"(Col_\" + col_clean + \") AS Col_\" + col_clean\n",
    "            \n",
    "            if m >= max(range(0,len(col_df.iloc[:,0]))):\n",
    "                agg_qry += agg_prt\n",
    "            else:\n",
    "                agg_qry += agg_prt + \", \"\n",
    "                \n",
    "        ## Group By number of columns\n",
    "        grp_qry =\"\"\n",
    "        for k in range(0, len(index_cols)):\n",
    "            grp_col = str(k+1)\n",
    "            if k == max(range(0, len(index_cols))):\n",
    "                grp_qry += grp_col\n",
    "            else:\n",
    "                grp_qry += grp_col + \", \"\n",
    "                \n",
    "\n",
    "        qry_1 = \"WITH Q1 AS (SELECT \" + idx_fin + \", \" + case_qry + \" \" + \" FROM `\" + db_name + \".\" + table_name + \"`)\"\n",
    "        \n",
    "        qry_2 = \" SELECT \" + idx_fin + \", \" + agg_qry +\" FROM Q1 GROUP BY \" + grp_qry \n",
    "        \n",
    "        final_qry = qry_1 + qry_2\n",
    "        \n",
    "        return final_qry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_col = \"vendor_name\"\n",
    "user_tbl = \"R30day_liquor\"\n",
    "user_db = \"project_id.mayank\"\n",
    "user_val = \"sale_dollars\" #by default put 1\n",
    "user_index = [\"city\", \"county\"] #list of index columns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "liq_qry = bq_custom_pivot(user_db, user_tbl, user_index, user_col, user_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_query = bq.Query(liq_qry)\n",
    "liquor_job = liq_query.execute(output_options = bq.QueryOutput.table(name='mayank.liqtry', \n",
    "                                                                    mode='overwrite'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON combined column to BigQuery columns Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a function to separate and write a query to read columns from a json string into a SQL query to create a dataset with all the json columns: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the database name, table name, json column and any additional columns you may want to select\n",
    "\n",
    "def jsontocol(db_name, table_name, json_col, additional_cols = None):\n",
    "    json_sql = \"SELECT \" + json_col + \" FROM `\" + db_name + \".\" + table_name + \"`\" + \" WHERE \" + json_col + \" IS NOT NULL LIMIT 1\" \n",
    "    \n",
    "    json_qry = bq.Query(json_sql)\n",
    "    json_element = json_qry.execute(output_options = bq.QueryOutput.dataframe()).result()\n",
    "    json_element = json_element.iloc[0,0]\n",
    "    \n",
    "    # identifying and cleaning the json column headers\n",
    "    json_clean = re.findall(\"{\\\"\\w*|,\\\"\\w*\", json_element)\n",
    "    \n",
    "    col_list = [re.sub(\"[\\\"\\,{]\", \"\", x) for x in json_clean]\n",
    "    \n",
    "    json_finalqry = \"\"\n",
    "    for i in range(0, len(col_list)):\n",
    "        \n",
    "        str_json = (\"JSON_EXTRACT_SCALAR(\" + json_col + \",\" +  \"'$.\" + col_list[i] + \"') AS \" + col_list[i])\n",
    "        if i == max(range(0, len(col_list))):\n",
    "            json_finalqry += str_json\n",
    "        else:\n",
    "            json_finalqry += str_json + \", \"\n",
    "    \n",
    "    \n",
    "    # iterating through the additional columns specified above (by default its none)\n",
    "    add_cols_fin = \"\"\n",
    "    if additional_cols != None:\n",
    "        for j in range(0, len(additional_cols)):\n",
    "            add_cols = additional_cols[j]\n",
    "\n",
    "            if j == max(range(0, len(additional_cols))):\n",
    "                add_cols_fin += add_cols\n",
    "            else:\n",
    "                add_cols_fin += add_cols + \", \"\n",
    "        \n",
    "    final_query = \"SELECT \" + add_cols_fin + \", \" + json_finalqry + \" FROM `\" + db_name + \".\" + table_name + \"`\"\n",
    "        \n",
    "    return final_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_qry = jsontocol(\"database_name\", # database name\n",
    "                     \"table_name\", # table name\n",
    "                     \"json_dimensions\", # column with the json string\n",
    "                     [\"col1\",\"col2\"]) # other columns you want to select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_write_qry = bq.Query(user_qry)\n",
    "json_write_job = json_write_qry.execute(output_options = bq.QueryOutput.table(name='mayank.json_table_name', \n",
    "                                                                    mode='overwrite'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
